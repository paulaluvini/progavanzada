{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "96YBFypXjXQQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "lo-dGk-fjdC7",
    "outputId": "6359098e-dca7-428a-8652-3b75b33ff48e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: double coverage amount , same payment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: storage meeting  ladies and gentlemen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: grades  pam ,  another team :  elena ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: contact info  fyi !  - - - - - - - - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : hi :  thanks vince :  could you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: double coverage amount , same payment...     1\n",
       "1  Subject: storage meeting  ladies and gentlemen...     0\n",
       "2  Subject: grades  pam ,  another team :  elena ...     0\n",
       "3  Subject: contact info  fyi !  - - - - - - - - ...     0\n",
       "4  Subject: re : hi :  thanks vince :  could you ...     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = pd.read_csv('training.csv')\n",
    "df_test = pd.read_csv('testing.csv')\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qZ_TRU50jgvr",
    "outputId": "ccee736c-a6f5-4b2c-b0b5-6c88d9c53e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2395\n"
     ]
    }
   ],
   "source": [
    "#Para ver si la muestra está balanceada. Vemos que no lo está, pero tampoco es un caso extremo.\n",
    "a = df_training.sum(axis = 0, skipna = True)\n",
    "b = df_training.count()\n",
    "Balance = a['spam'] / b['spam']\n",
    "print(Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NgQU5e1gkvFs"
   },
   "outputs": [],
   "source": [
    "#Eliminar caracteres que no sean los siguientes:\n",
    "\n",
    "#Elegimos los que creemos convenientes\n",
    "pattern = '([^A-Za-z0-9 @]|Subject)'\n",
    "res = []\n",
    "\n",
    "for t in df_training[\"text\"]:\n",
    "   res.append(re.sub(pattern, '', t))\n",
    "\n",
    "clas = df_training[\"spam\"]\n",
    "df_training = pd.DataFrame(list(zip(res, clas)), columns = 'text spam'.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "_8E2kElI7X7b",
    "outputId": "5f8f3858-b61b-439f-c8b7-5d1d1bb08ddc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>double coverage amount  same payment    uyz  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storage meeting  ladies and gentlemen   due t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grades  pam   another team   elena chilkina  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contact info  fyi                         for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>re  hi   thanks vince   could you give me mik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>california update 3  06  01  executive summar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>aram  rick   aram is coming to houston  in my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>re  hello from vince kaminski at enron  vince...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>vince   i  ll have him e  mail you a cv   i  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>re  conference  phelim   thanks again for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0      double coverage amount  same payment    uyz  ...     1\n",
       "1      storage meeting  ladies and gentlemen   due t...     0\n",
       "2      grades  pam   another team   elena chilkina  ...     0\n",
       "3      contact info  fyi                         for...     0\n",
       "4      re  hi   thanks vince   could you give me mik...     0\n",
       "...                                                 ...   ...\n",
       "3995   california update 3  06  01  executive summar...     0\n",
       "3996   aram  rick   aram is coming to houston  in my...     0\n",
       "3997   re  hello from vince kaminski at enron  vince...     0\n",
       "3998   vince   i  ll have him e  mail you a cv   i  ...     0\n",
       "3999   re  conference  phelim   thanks again for the...     1\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "XnTeDhuCkwRh",
    "outputId": "166f1c5f-0295-4457-8515-67427cc06f23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/paulaluvini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/paulaluvini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "fs =[]\n",
    "fs_df = []\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for t in df_training['text']: \n",
    "\n",
    "  word_tokens = word_tokenize(t) \n",
    "  \n",
    "  filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "  filtered_sentence = [] \n",
    "  \n",
    "  for w in word_tokens: \n",
    "      if w not in stop_words: \n",
    "         filtered_sentence.append(w)\n",
    "         #fsentence = ' '.join([str(elem) for elem in filtered_sentence])\n",
    "  #fs_df.append(fsentence)\n",
    "  fs.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "2qB7UI15k02n",
    "outputId": "f66d9d0d-03fa-43c0-af45-6c5026586f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  spam\n",
      "0  [double, coverage, amount, payment, uyz, save,...     1\n",
      "1  [storage, meeting, ladies, gentlemen, due, una...     0\n",
      "2  [grades, pam, another, team, elena, chilkina, ...     0\n",
      "3  [contact, info, fyi, forwarded, shirley, crens...     0\n",
      "4  [hi, thanks, vince, could, give, mike, roberts...     0\n"
     ]
    }
   ],
   "source": [
    "#Guardo los mails limpios de stopwords en el dataframe.\n",
    "\n",
    "clas = df_training[\"spam\"]\n",
    "df_training = pd.DataFrame((list(zip(fs, clas))), columns = 'text spam'.split())\n",
    "print(df_training.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z-unYtkt-U3g"
   },
   "outputs": [],
   "source": [
    "#for i in range(len(df_training['text'])):\n",
    " # df_training['text'].iloc[i] = \" \".join(df_training['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "TM7SreiGATwo",
    "outputId": "0a37131a-a0aa-4cf9-8249-45459b81eb24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [double, coverage, amount, payment, uyz, save,...\n",
       "1       [storage, meeting, ladies, gentlemen, due, una...\n",
       "2       [grades, pam, another, team, elena, chilkina, ...\n",
       "3       [contact, info, fyi, forwarded, shirley, crens...\n",
       "4       [hi, thanks, vince, could, give, mike, roberts...\n",
       "                              ...                        \n",
       "3995    [california, update, 3, 06, 01, executive, sum...\n",
       "3996    [aram, rick, aram, coming, houston, view, expl...\n",
       "3997    [hello, vince, kaminski, enron, vince, audienc...\n",
       "3998    [vince, e, mail, cv, happy, speak, power, risk...\n",
       "3999    [conference, phelim, thanks, invitation, speak...\n",
       "Name: text, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tfdym2c1Iwu7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "CMl4KwC7E2Xc",
    "outputId": "c05f3071-98b6-43e2-c348-2a7c2791152e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/paulaluvini/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/paulaluvini/whatever/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "contador =0\n",
    "lemmatized = []\n",
    "for t in df_training['text']:  \n",
    "  res = []\n",
    "  #doc = ' '.join([str(elem) for elem in t])\n",
    "  for word in t:\n",
    "    res.append( lemmatizer.lemmatize(word))\n",
    "  df_training['text'].iloc[contador] = \" \".join(res)\n",
    "  contador = contador +1 \n",
    "  #lemmatized.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "KsXjFAcVPdvK",
    "outputId": "733d7a7e-5b23-489c-b35b-70409b0d64e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       double coverage amount payment uyz save 75 ter...\n",
       "1       storage meeting lady gentleman due unavailabil...\n",
       "2       grade pam another team elena chilkina robert j...\n",
       "3       contact info fyi forwarded shirley crenshaw ho...\n",
       "4       hi thanks vince could give mike robert contact...\n",
       "                              ...                        \n",
       "3995    california update 3 06 01 executive summary co...\n",
       "3996    aram rick aram coming houston view explore pos...\n",
       "3997    hello vince kaminski enron vince audience cons...\n",
       "3998    vince e mail cv happy speak power risk confere...\n",
       "3999    conference phelim thanks invitation speak conf...\n",
       "Name: text, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NltzW1NEQIk0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "opmT59sV6O6r"
   },
   "outputs": [],
   "source": [
    "def review_messages(msg):\n",
    "    # converting messages to lowercase\n",
    "    msg = msg.lower()\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7bC0GUeDBaX6"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['text'] = df_training['text'].apply(review_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "bBDZpBaYDbzy",
    "outputId": "b3b84b6e-875e-472f-edeb-31aff0d952ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       double coverage amount payment uyz save 75 ter...\n",
       "1       storage meeting lady gentleman due unavailabil...\n",
       "2       grade pam another team elena chilkina robert j...\n",
       "3       contact info fyi forwarded shirley crenshaw ho...\n",
       "4       hi thanks vince could give mike robert contact...\n",
       "                              ...                        \n",
       "3995    california update 3 06 01 executive summary co...\n",
       "3996    aram rick aram coming houston view explore pos...\n",
       "3997    hello vince kaminski enron vince audience cons...\n",
       "3998    vince e mail cv happy speak power risk confere...\n",
       "3999    conference phelim thanks invitation speak conf...\n",
       "Name: text, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UfMRVHrt6PPS"
   },
   "outputs": [],
   "source": [
    "\n",
    "data['label'] = df_training['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oSj4Rjb56PWs"
   },
   "outputs": [],
   "source": [
    "X_train = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw1SpX8kCrxv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "latzb-Ec6PaG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "id": "iEK5xDRyTX6n",
    "outputId": "6d10ae3d-a661-4817-b7d8-0167ba9118c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3583)\t0.09485154813638648\n",
      "  (0, 22628)\t0.11934565322519695\n",
      "  (0, 21431)\t0.10030583292385752\n",
      "  (0, 3917)\t0.08207343354188217\n",
      "  (0, 21384)\t0.11833803914978167\n",
      "  (0, 19668)\t0.07202852189341878\n",
      "  (0, 4311)\t0.09852960184623051\n",
      "  (0, 24234)\t0.09225899733502023\n",
      "  (0, 21518)\t0.05578808348692068\n",
      "  (0, 22167)\t0.20711027712663388\n",
      "  (0, 14814)\t0.10804951199690023\n",
      "  (0, 18130)\t0.07794290439018751\n",
      "  (0, 16400)\t0.07794290439018751\n",
      "  (0, 4307)\t0.07338448855437621\n",
      "  (0, 12311)\t0.1738852986936335\n",
      "  (0, 12778)\t0.13888664850258975\n",
      "  (0, 3121)\t0.06425544025728223\n",
      "  (0, 16990)\t0.23667607829956333\n",
      "  (0, 16700)\t0.07437745719036698\n",
      "  (0, 7278)\t0.0658281107635284\n",
      "  (0, 26997)\t0.06055489055488767\n",
      "  (0, 21073)\t0.08665718997994157\n",
      "  (0, 23303)\t0.06367217920279365\n",
      "  (0, 7058)\t0.09403522841264722\n",
      "  (0, 11913)\t0.11560588978774805\n",
      "  :\t:\n",
      "  (3999, 16424)\t0.10591168646568293\n",
      "  (3999, 16952)\t0.07457871256001215\n",
      "  (3999, 19027)\t0.05534810002808194\n",
      "  (3999, 21682)\t0.060977994699461024\n",
      "  (3999, 367)\t0.05022472676281651\n",
      "  (3999, 25236)\t0.08238597579060948\n",
      "  (3999, 13951)\t0.12017238417238287\n",
      "  (3999, 772)\t0.040077802783739916\n",
      "  (3999, 27802)\t0.05961338518298105\n",
      "  (3999, 11903)\t0.06533465474118873\n",
      "  (3999, 26705)\t0.039915699940304104\n",
      "  (3999, 27114)\t0.08811175960555832\n",
      "  (3999, 25596)\t0.08486243843297202\n",
      "  (3999, 11703)\t0.057264679102391566\n",
      "  (3999, 25873)\t0.03406311333645033\n",
      "  (3999, 6702)\t0.036301093674071916\n",
      "  (3999, 10851)\t0.03318528336809796\n",
      "  (3999, 7503)\t0.038073539023471846\n",
      "  (3999, 296)\t0.04424212565994734\n",
      "  (3999, 15720)\t0.03815342107465998\n",
      "  (3999, 28374)\t0.09528411779278048\n",
      "  (3999, 26702)\t0.05306654718984461\n",
      "  (3999, 1131)\t0.05242191632562174\n",
      "  (3999, 7808)\t0.2592873265158945\n",
      "  (3999, 17784)\t0.053734393914934064\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ypfpzuj9DvYs"
   },
   "outputs": [],
   "source": [
    "y_train = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "_OsZ19FkDvjv",
    "outputId": "c220c81c-9b91-4ca0-ad59-68bf82709bdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "5vKWuk4TjIhN",
    "outputId": "a346ffcf-2ed8-4de2-82bd-f674ff524556"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rzwxR7q6ETWx"
   },
   "outputs": [],
   "source": [
    "#Eliminar caracteres que no sean los siguientes:\n",
    "\n",
    "#Elegimos los que creemos convenientes\n",
    "pattern = '([^A-Za-z0-9 @]|Subject)'\n",
    "res = []\n",
    "\n",
    "for t in df_test[\"text\"]:\n",
    "   res.append(re.sub(pattern, '', t))\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame(list(zip(res)), columns = 'text'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "BDXWiOgcEXlF",
    "outputId": "70550fb7-a2d0-4c2b-e845-84d8032de9b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview schedule for greg mikkelson  attach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>re  we have all your favorite programs at inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re  mission impossible  hr associate groups r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reply a  s  a  p  united trust bank limited  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>re  clewlow  strickland derivatives book  and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>6  50  annuity w  4  05  lifetime bailout  10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>follow  up on siam workshop  i am forwarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>regulatory var  tentative agenda for the rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>fw  fw  question about ernie  vince   i left ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>re  power play book  vince   i  m really feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0      interview schedule for greg mikkelson  attach...\n",
       "1      re  we have all your favorite programs at inc...\n",
       "2      re  mission impossible  hr associate groups r...\n",
       "3      reply a  s  a  p  united trust bank limited  ...\n",
       "4      re  clewlow  strickland derivatives book  and...\n",
       "...                                                 ...\n",
       "1723   6  50  annuity w  4  05  lifetime bailout  10...\n",
       "1724   follow  up on siam workshop  i am forwarding ...\n",
       "1725   regulatory var  tentative agenda for the rese...\n",
       "1726   fw  fw  question about ernie  vince   i left ...\n",
       "1727   re  power play book  vince   i  m really feel...\n",
       "\n",
       "[1728 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "E5YuC0KYFZyE"
   },
   "outputs": [],
   "source": [
    "\n",
    "fs =[]\n",
    "fs_df = []\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for t in df_test['text']: \n",
    "\n",
    "  word_tokens = word_tokenize(t) \n",
    "  \n",
    "  filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "  filtered_sentence = [] \n",
    "  \n",
    "  for w in word_tokens: \n",
    "      if w not in stop_words: \n",
    "         filtered_sentence.append(w)\n",
    "         #fsentence = ' '.join([str(elem) for elem in filtered_sentence])\n",
    "  #fs_df.append(fsentence)\n",
    "  fs.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nEU0Rs5UFZ0y"
   },
   "outputs": [],
   "source": [
    "df_test= pd.DataFrame((list(zip(fs))), columns = 'text'.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "xseBU0wvRIo8",
    "outputId": "dce58697-bd0a-431e-b626-f5a38cfb86ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  [interview, schedule, greg, mikkelson, attache...\n",
      "1  [favorite, programs, incredibly, low, prices, ...\n",
      "2  [mission, impossible, hr, associate, groups, r...\n",
      "3  [reply, p, united, trust, bank, limited, 80, h...\n",
      "4  [clewlow, strickland, derivatives, book, andy,...\n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "2GB_hBNTFZ3j",
    "outputId": "b49f09c4-3034-4db3-c68c-b744c627da5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/paulaluvini/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "contador =0\n",
    "lemmatized = []\n",
    "for t in df_test['text']:  \n",
    "  res = []\n",
    "  #doc = ' '.join([str(elem) for elem in t])\n",
    "  for word in t:\n",
    "    res.append( lemmatizer.lemmatize(word))\n",
    "  df_test['text'].iloc[contador] = \" \".join(res)\n",
    "  contador = contador +1 \n",
    "  #lemmatized.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "ep4KIFxFFZ6F",
    "outputId": "efe3c486-c6cf-4922-d5be-d4fa8a84f642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview schedule greg mikkelson attached ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>favorite program incredibly low price cheapest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mission impossible hr associate group recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reply p united trust bank limited 80 haymarket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clewlow strickland derivative book andy please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>6 50 annuity w 4 05 lifetime bailout 10 penalt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>follow siam workshop forwarding attention resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>regulatory var tentative agenda research lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>fw fw question ernie vince left voice message ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>power play book vince really feeling like blin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     interview schedule greg mikkelson attached ple...\n",
       "1     favorite program incredibly low price cheapest...\n",
       "2     mission impossible hr associate group recommen...\n",
       "3     reply p united trust bank limited 80 haymarket...\n",
       "4     clewlow strickland derivative book andy please...\n",
       "...                                                 ...\n",
       "1723  6 50 annuity w 4 05 lifetime bailout 10 penalt...\n",
       "1724  follow siam workshop forwarding attention resu...\n",
       "1725  regulatory var tentative agenda research lunch...\n",
       "1726  fw fw question ernie vince left voice message ...\n",
       "1727  power play book vince really feeling like blin...\n",
       "\n",
       "[1728 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "e7Ey4FjgFZ8f"
   },
   "outputs": [],
   "source": [
    "#for i in range(len(df_test['text'])):\n",
    " # df_test['text'].iloc[i] = \" \".join(df_test['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rg4-hp9fFZ_B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rckWpbnIEXoE"
   },
   "outputs": [],
   "source": [
    "df_test['text'] = df_test['text'].apply(review_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ni-2ehyEEXtr"
   },
   "outputs": [],
   "source": [
    "X_test = df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CgnxEOfLEXwb"
   },
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AmkZ-PsUGz76"
   },
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_SIkkunvG0AO"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uBAIcvZ_Hefe"
   },
   "outputs": [],
   "source": [
    "submission['Category']= y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "rxfRAnxJHtWF"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickl = {\n",
    "    'vectorizer': vectorizer,\n",
    "    'regressor': svm\n",
    "}\n",
    "pickle.dump( pickl, open( 'models' + \".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLSz24m-k4AO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGeoE0aYlNsk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fk6Kmim3li6y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFU25gOGsxhQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcz26E3usz-R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATg4_ah-lr1L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
